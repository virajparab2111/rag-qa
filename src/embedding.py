from typing import List, Any
from langchain_text_splitters import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer
import numpy as np
from src.data_loader import load_all_documents


class EmbeddingPipeline:
    def __init__(
        self,
        model_name: str = "all-MiniLM-L6-v2",
        chunk_size: int = 1000,
        chunk_overlap: int = 200
    ):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.model = SentenceTransformer(model_name)
        print(f"[INFO] Loaded embedding model: {model_name}")

    # --------------------------------------------------
    # Chunk documents with source-aware metadata
    # --------------------------------------------------
    def chunk_documents(self, documents: List[Any]) -> List[Any]:
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )

        chunks = splitter.split_documents(documents)

        # Assign deterministic source IDs
        for idx, chunk in enumerate(chunks):
            chunk.metadata = chunk.metadata or {}
            chunk.metadata["source_id"] = f"Source {idx + 1}"

        print(f"[INFO] Split {len(documents)} documents into {len(chunks)} chunks.")
        return chunks

    # --------------------------------------------------
    # Embed chunks (metadata preserved externally)
    # --------------------------------------------------
    def embed_chunks(self, chunks: List[Any]) -> np.ndarray:
        texts = [chunk.page_content for chunk in chunks]

        print(f"[INFO] Generating embeddings for {len(texts)} chunks...")
        embeddings = self.model.encode(
            texts,
            show_progress_bar=True,
            convert_to_numpy=True,
            normalize_embeddings=True
        )

        print(f"[INFO] Embeddings shape: {embeddings.shape}")
        return embeddings


# --------------------------------------------------
# Example usage
# --------------------------------------------------
if __name__ == "__main__":
    docs = load_all_documents(
        r"C:\Users\Asus_owner\PycharmProjects\rag\pdf_data"
    )
    emb_pipe = EmbeddingPipeline()
    chunks = emb_pipe.chunk_documents(docs)
    embeddings = emb_pipe.embed_chunks(chunks)

    print("[INFO] Example chunk metadata:", chunks[0].metadata)
    print("[INFO] Example embedding:", embeddings[0])
